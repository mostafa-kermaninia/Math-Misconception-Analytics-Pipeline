name: Data Pipeline CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  pipeline-check:
    runs-on: ubuntu-latest
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: root
          MYSQL_DATABASE: University_DB
          MYSQL_USER: workbench_user
          MYSQL_PASSWORD: 1
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping -h 127.0.0.1 -uroot -proot"
          --health-interval=15s
          --health-timeout=10s
          --health-retries=10
          --default-authentication-plugin=mysql_native_password

    steps:
      - uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install cryptography pymysql
      
      - name: Wait for MySQL to be ready
        run: |
          # ایجاد فایل پیکربندی موقت
          echo "[client]\nuser=root\npassword=root\nhost=127.0.0.1" > ~/.my.cnf
          chmod 600 ~/.my.cnf
          
          # افزایش زمان انتظار و تعداد تلاش‌ها
          for i in {1..15}; do
            if mysqladmin ping --silent; then
              echo "MySQL is ready!"
              mysql -e "CREATE DATABASE IF NOT EXISTS University_DB;"
              mysql -e "CREATE USER IF NOT EXISTS 'workbench_user'@'%' IDENTIFIED WITH mysql_native_password BY '1';"
              mysql -e "GRANT ALL PRIVILEGES ON University_DB.* TO 'workbench_user'@'%';"
              mysql -e "FLUSH PRIVILEGES;"
              exit 0
            else
              echo "Waiting for MySQL... Attempt $i"
              sleep 10
            fi
          done
          echo "::error::Failed to connect to MySQL after 15 attempts"
          exit 1
      
      - name: Verify dataset files
        run: |
          if [ ! -f "database/train.csv" ] || [ ! -f "database/misconception_mapping.csv" ]; then
            echo "::error::Dataset files are missing!"
            exit 1
          fi
          echo "Dataset files verified successfully"
      
      - name: Run database import script
        env:
          DB_HOST: 127.0.0.1
          DB_USER: workbench_user
          DB_PASSWORD: 1
          DB_NAME: University_DB
        run: python scripts/database_operations/import_csv_to_db.py
      
      - name: Run main pipeline
        env:
          DB_HOST: 127.0.0.1
          DB_USER: workbench_user
          DB_PASSWORD: 1
          DB_NAME: University_DB
        run: python pipeline.py